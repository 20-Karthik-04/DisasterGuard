# ğŸš¨ DisasterGuard - AI-Powered Real-Time Disaster Detection System

[![Python](https://img.shields.io/badge/Python-3.11.9-blue.svg)](https://python.org)
[![Node.js](https://img.shields.io/badge/Node.js-16+-green.svg)](https://nodejs.org)
[![Flask](https://img.shields.io/badge/Flask-3.0.3-red.svg)](https://flask.palletsprojects.com)
[![Deployment](https://img.shields.io/badge/Deployed-Render-purple.svg)](https://render.com)

DisasterGuard is an intelligent disaster detection and analysis system that uses machine learning and natural language processing to identify and classify disaster-related content from social media posts in real-time. The system provides comprehensive analysis including disaster classification, location extraction, sentiment analysis, and multi-language support.

## ğŸ¯ Problem Statement

In emergency situations, social media becomes a critical source of real-time information about disasters. However, the massive volume of posts makes it impossible to manually monitor and identify genuine disaster reports. Traditional keyword-based systems suffer from:

- **High false positive rates** (casual use of disaster terms)
- **Language barriers** in multilingual regions like India
- **Inability to understand context** and urgency
- **Poor location extraction** from unstructured text
- **Lack of sentiment analysis** for emergency prioritization

## ğŸš€ Key Features

### ğŸ§  **Intelligent Text Analysis**
- **Advanced Preprocessing**: URL removal, hashtag processing, mention handling
- **Context Recognition**: Distinguishes real disasters from metaphorical usage
- **Dynamic Thresholds**: Adaptive confidence based on context strength (0.25-0.6 range)

### ğŸŒ **Multi-Language Processing**
- **Language Detection**: Automatic identification of 12+ languages
- **Translation Pipeline**: Google Translate with TextBlob fallback
- **Regional Support**: Specialized handling for Hindi, Bengali, Tamil, Telugu, and other Indian languages

### ğŸ“ **Location Intelligence**
- **Named Entity Recognition**: Advanced location extraction using spaCy and TextBlob
- **Geographic Database**: 150+ Indian cities and states with aliases
- **Pattern Matching**: Contextual location detection ("in Delhi", "at Mumbai", "from Bangalore")

### ğŸ·ï¸ **Disaster Classification**
- **49 Disaster Categories**: From earthquakes to cyber attacks
- **Comprehensive Keywords**: 500+ disaster-related terms across all categories
- **Weighted Scoring**: Multi-word keywords receive higher priority scores

### ğŸ’­ **Sentiment & Urgency Analysis**
- **Disaster-Specific Sentiment**: Urgent/Fearful, Highly Negative, Concerned/Informative
- **Emergency Indicators**: Detection of help requests, panic signals, and urgency words
- **Context-Aware Classification**: Different sentiment handling for disaster vs. normal content

### ğŸ›¡ï¸ **False Positive Filtering**
- **Pattern Recognition**: 10+ regex patterns for common false positives
- **Contextual Validation**: Ensures proper disaster context indicators
- **Metaphor Detection**: Filters casual usage ("movie disaster", "cooking disaster", "traffic disaster")

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚â”€â”€â”€â–¶â”‚  Node.js API    â”‚â”€â”€â”€â–¶â”‚  Python ML      â”‚
â”‚   (HTML/CSS/JS) â”‚    â”‚   (Express)     â”‚    â”‚   Service       â”‚
â”‚     Port 3000   â”‚    â”‚    Port 3000    â”‚    â”‚   Port 3001     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                        â”‚
                              â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Static    â”‚        â”‚   ML Models â”‚
                       â”‚   Assets    â”‚        â”‚   & Data    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Component Breakdown**

**ğŸ–¥ï¸ Frontend Layer (Node.js + Express)**
- Modern responsive web interface with real-time analysis
- Batch processing capabilities and results visualization
- Multiple pages: Home, About, Feedback, Model Insights, Motivation

**ğŸ¤– ML Processing Service (Python + Flask)**
- Core machine learning and NLP processing
- Multi-language detection, translation, and analysis
- Location extraction, sentiment analysis, and classification

**ğŸ“Š Data Layer**
- Pre-trained scikit-learn models (Logistic Regression, TF-IDF Vectorizer, StandardScaler)
- Comprehensive knowledge bases (disaster keywords, city aliases, location databases)
- JSON-based configuration files for easy updates

## ğŸ”§ Technologies Used

### **Backend Technologies**
- **Python 3.11.9**: Core ML processing language
- **Flask 3.0.3**: Web framework for ML API
- **Node.js**: Frontend server and API gateway
- **Express.js**: Web application framework

### **Machine Learning & NLP**
- **scikit-learn 1.5.1**: Machine learning algorithms (Logistic Regression)
- **NLTK 3.9.1**: Natural language processing and sentiment analysis
- **TextBlob 0.17.1**: Text processing and language detection fallback
- **langdetect 1.0.9**: Primary language detection
- **deep-translator 1.11.4**: Multi-language translation (Python 3.13 compatible)

### **Data Processing**
- **NumPy 1.26.4**: Numerical computations
- **Joblib 1.4.2**: Model serialization and loading
- **Requests 2.32.3**: HTTP client for API calls

### **Web Technologies**
- **HTML5/CSS3**: Modern responsive frontend with CSS Grid and Flexbox
- **JavaScript (ES6+)**: Interactive user interface with async/await
- **Font Awesome 6.4.0**: Comprehensive icon library
- **Google Fonts**: Poppins and Roboto Mono typography

### **Deployment & DevOps**
- **Gunicorn 23.0.0**: WSGI server for production deployment
- **Flask-CORS 5.0.0**: Cross-origin resource sharing
- **Git**: Version control with comprehensive commit history
- **Render**: Cloud deployment platform with automatic deployments

## ğŸš€ Quick Start

### **Prerequisites**
- Python 3.11+ (recommended 3.11.9 for deployment compatibility)
- Node.js 16+ 
- Git

### **Installation**

1. **Clone the repository:**
```bash
git clone https://github.com/20-Karthik-04/DisasterGuard.git
cd DisasterGuard
```

2. **Set up Python environment:**
```bash
cd python_service
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Set up Node.js environment:**
```bash
cd ../node_backend
npm install
```

### **Running the Application**

1. **Start the Python ML service:**
```bash
cd python_service
source venv/bin/activate  # Ensure virtual environment is activated
python app.py
# Service will start on http://localhost:3001
```

2. **Start the Node.js frontend (in a new terminal):**
```bash
cd node_backend
npm start
# Frontend will start on http://localhost:3000
```

3. **Open your browser and navigate to `http://localhost:3000`**

### **Testing the System**

Run the comprehensive test suite:
```bash
cd DisasterGuard
source venv/bin/activate
python test_predictions.py
```

## ğŸ“ Project Structure

```
DisasterGuard/
â”œâ”€â”€ ğŸ“ python_service/              # ML Processing Service
â”‚   â”œâ”€â”€ ğŸ app.py                   # Main Flask application (733 lines)
â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ ğŸ¤– lr_model.pkl            # Trained Logistic Regression model
â”‚   â”œâ”€â”€ ğŸ“Š vectorizer.pkl          # TF-IDF Vectorizer
â”‚   â”œâ”€â”€ âš–ï¸ scaler.pkl              # StandardScaler for feature scaling
â”‚   â”œâ”€â”€ ğŸ·ï¸ disaster_keywords.json  # 49 disaster categories with keywords
â”‚   â”œâ”€â”€ ğŸŒ city_aliases.json       # Global city aliases and abbreviations
â”‚   â”œâ”€â”€ ğŸ“ disaster_errors.log     # Error logging file
â”‚   â””â”€â”€ ğŸ runtime.txt             # Python version for deployment
â”œâ”€â”€ ğŸ“ node_backend/               # Frontend Service
â”‚   â”œâ”€â”€ ğŸš€ app.js                  # Express server configuration
â”‚   â”œâ”€â”€ ğŸ“ routes/
â”‚   â”‚   â””â”€â”€ ğŸ›£ï¸ predict.js          # API routing for predictions
â”‚   â”œâ”€â”€ ğŸ“ public/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ templates/          # HTML pages
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ  index.html      # Main interface (733 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ â„¹ï¸ about-us.html   # About page
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ’­ feedback.html   # Feedback form
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ’¡ motivation.html # Project motivation
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ” model-insight.html # Model details
â”‚   â”‚   â””â”€â”€ ğŸ“ static/             # CSS, JS, images
â”‚   â””â”€â”€ ğŸ“¦ package.json            # Node.js dependencies
â”œâ”€â”€ ğŸ§ª test_predictions.py         # Comprehensive testing script (268 lines)
â”œâ”€â”€ ğŸ“Š IMPROVEMENTS.md             # Detailed improvement documentation
â”œâ”€â”€ ğŸ“– README.md                   # This file
â”œâ”€â”€ ğŸ¤– rf_pipeline_model_bert_only.joblib # Alternative model file
â”œâ”€â”€ ğŸ“ train.txt                   # Training data sample
â””â”€â”€ ğŸš« .gitignore                  # Git ignore rules
```

## ğŸ”„ Data Flow Pipeline

1. **Input Processing**: Tweet text received via REST API
2. **Preprocessing**: Text cleaning, URL removal, hashtag processing
3. **Language Detection**: Automatic language identification using langdetect
4. **Translation**: Convert non-English text to English using deep-translator
5. **Feature Extraction**: TF-IDF vectorization and standard scaling
6. **ML Prediction**: Logistic Regression model generates disaster probability
7. **Context Analysis**: Dynamic threshold adjustment based on context strength
8. **Location Extraction**: NER and pattern matching for geographic entities
9. **Sentiment Analysis**: VADER sentiment with disaster-specific categories
10. **Response Generation**: Comprehensive JSON result with all metadata

## ğŸŒ Deployment

### **Render Deployment**
The application is configured for deployment on Render cloud platform:

- **Python Service**: Automatically deploys from `python_service/` directory
- **Runtime**: Python 3.11.9 (specified in `runtime.txt`)
- **Dependencies**: Auto-installed from `requirements.txt`
- **Start Command**: `gunicorn --bind 0.0.0.0:$PORT app:app`

### **Environment Configuration**
```bash
# Production environment variables
FLASK_ENV=production
NLTK_DATA=/app/nltk_data
PORT=3001  # Render assigns this automatically
```

## ğŸ”® Future Enhancements

### **Immediate Improvements**
1. **Enhanced ML Models**: Implement BERT-based transformers for better accuracy
2. **Real-time Streaming**: Integration with Twitter API for live monitoring
3. **Geographic Clustering**: Spatial analysis of disaster reports
4. **Image Analysis**: OCR and image classification for multimedia posts

### **Scalability Features**
1. **Caching Layer**: Redis for frequently accessed data and model caching
2. **Load Balancing**: Multiple service instances with container orchestration
3. **Database Integration**: PostgreSQL for historical analysis and user management
4. **Monitoring**: Application performance monitoring with alerts

### **Advanced Analytics**
1. **Temporal Analysis**: Time-series analysis for disaster progression tracking
2. **Credibility Scoring**: Source reliability and verification metrics
3. **Impact Assessment**: Severity scoring based on multiple factors
4. **Predictive Analytics**: Early warning systems based on social media trends

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** with proper documentation
4. **Add tests** for new functionality
5. **Commit changes**: `git commit -m 'Add amazing feature'`
6. **Push to branch**: `git push origin feature/amazing-feature`
7. **Submit a Pull Request** with detailed description



---
